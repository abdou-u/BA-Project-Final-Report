\chapter{Implementation}

\section{Introduction}
This chapter details the implementation of the models, algorithms, and simulations discussed in this study. The focus is on providing the necessary code snippets and explaining the logic behind the implementations. Additionally, we discuss the computational complexity of each algorithm.

\section{Model Structures and Algorithms}

\subsection{Grid-Based Model Implementation}
We chose to use NumPy for grid-based algorithms due to its efficiency in handling large arrays and performing mathematical operations. NumPy's operations are optimized for performance, making it faster than using a network library like NetworkX for grid-based structures. Additionally, we used the JIT (Just-In-Time) compilation feature from the Numba library to further optimize our distance calculations, ensuring that our algorithms run efficiently even on large grids.

\subsubsection{Jordan Centrality}
The Jordan Center Identification algorithm utilizes the Breadth-First Search (BFS) to determine the central node that minimizes the maximum distance to all other nodes. This method calculates the centrality score for each candidate node, selecting the node with the highest score as the source.

\begin{algorithm}
\caption{Jordan Centrality using BFS}
\begin{algorithmic}[1]
\STATE Initialize centrality scores for each node.
\FOR{each candidate node}
    \STATE Perform BFS to calculate distances.
    \STATE Compute centrality score based on distances.
\ENDFOR
\STATE Select the node with the highest centrality score as the source.
\end{algorithmic}
\end{algorithm}

\textbf{Time Complexity:} The BFS algorithm has a time complexity of \(O(V + E)\), where \(V\) is the number of vertices (nodes) and \(E\) is the number of edges (connections). Since this algorithm is applied to each candidate node, the overall complexity can be considered \(O(N(V + E))\) where \(N\) is the number of candidate nodes.

\subsubsection{Center of Mass}
The Center of Mass algorithm calculates the mean position of all infected nodes and designates this point as the source of the infection. This method is computationally efficient but can be less accurate, especially near grid boundaries.

\begin{algorithm}
\caption{Center of Mass Algorithm}
\begin{algorithmic}[1]
\STATE Identify all boundary nodes.
\STATE Perform flood fill to isolate internal and external boundaries.
\STATE Calculate the centroid of the boundary nodes.
\STATE Designate the centroid as the source.
\end{algorithmic}
\end{algorithm}

\textbf{Time Complexity:} The flood fill algorithm has a time complexity of \(O(N)\), where \(N\) is the number of nodes in the grid. The overall complexity for finding the centroid is also \(O(N)\) since it requires visiting each node.

\subsubsection{Distance Analysis}
The Distance Analysis algorithm calculates the maximum Euclidean distance from each candidate node to any point on the boundary and identifies the node that minimizes this maximum distance.

\begin{algorithm}
\caption{Distance Analysis Algorithm}
\begin{algorithmic}[1]
\STATE Identify all boundary nodes.
\FOR{each candidate node}
    \STATE Calculate the maximum Euclidean distance to the boundary nodes.
    \STATE Track the node that minimizes this maximum distance.
\ENDFOR
\STATE Designate the node with the minimum maximum distance as the source.
\end{algorithmic}
\end{algorithm}

\textbf{Time Complexity:} The main operations in this algorithm involve iterating over the grid nodes and computing Euclidean distances. The time complexity is \(O(N \cdot M)\), where \(N\) is the number of nodes and \(M\) is the number of boundary nodes.

\subsection{Complex Network Models Implementation}
In this section, we focus on the implementation of centrality measures for source detection in complex network models. We use various centrality measures to identify the infection source within networks such as Erdős-Rényi graphs, Random Regular graphs, and Random Geometric graphs.

The centrality measures we implemented include those mentioned and explained in \ref{centrality_measure}, which are:

\begin{itemize}
    \item Eccentricity + Closeness Centrality
    \item Jordan Center
    \item Betweenness Centrality
    \item Eigenvector Centrality
    \item Closeness Centrality
\end{itemize}

We used the NetworkX library to implement these centrality measures. The library provides efficient functions to compute the various centrality metrics, allowing us to focus on integrating these measures into our source detection framework.

 Each centrality measure has its own strengths and weaknesses, and the choice of measure depends on the specific characteristics of the network and the requirements of the analysis.

This concludes the implementation section for the complex network models. Next, we will discuss the stochastic approach.

\subsection{Stochastic Approach Implementation}
In this section, we detail the implementation of the stochastic approach to model infection spread using the Gillespie Algorithm.

\subsubsection{Gillespie Algorithm}
The Gillespie Algorithm is used to simulate the time evolution of systems with random events, such as the spread of infectious diseases. Its flowchart is shown in Figure \ref{fig:gillespie_algorithm}.

It involves calculating propensities for each possible event, generating random numbers to determine the next event and its timing, and updating the system state accordingly. The following code snippet demonstrates the implementation of the Gillespie Algorithm for the SIRS model:

\begin{algorithm}
\caption{Gillespie Algorithm for SIRS Model}
\begin{algorithmic}[1]
\STATE Initialize S, I, R, and time.
\WHILE{time $<$ T}
    \STATE Calculate rates: infection, recovery, loss of immunity.
    \STATE Calculate total rate.
    \IF{total rate == 0}
        \STATE break.
    \ENDIF
    \STATE Draw time step from exponential distribution.
    \STATE Update time.
    \STATE Draw event type.
    \IF{infection event}
        \STATE Update S, I, R.
    \ELSIF{recovery event}
        \STATE Update S, I, R.
    \ELSIF{loss of immunity event}
        \STATE Update S, I, R.
    \ENDIF
\ENDWHILE
\end{algorithmic}
\end{algorithm}

\section{Conclusion}
In this chapter, we have detailed the implementation of the models, algorithms, and simulations used in this study to analyze the spread of infectious diseases. We provided code snippets for key components, including the grid-based models and stochastic approaches. 

For the grid-based models, we implemented three main algorithms: Jordan Centrality, Center of Mass, and Distance Analysis. Each algorithm was discussed in terms of its implementation details, time complexity, and space complexity. We used NumPy for efficient computation and the JIT compiler from Numba to optimize performance.

For the complex network models, we implemented various centrality measures such as Eccentricity + Closeness Centrality, Jordan Centrality, Betweenness Centrality, Eigenvector Centrality, and Closeness Centrality.

In the stochastic approach, we incorporated randomness into the models using the Gillespie Algorithm. The implementation of this method was described along with its computational complexity.

By implementing these models and algorithms, we were able to simulate the spread of infectious diseases in different network structures and compare the effectiveness of various source detection methods. The detailed implementation provided in this chapter serves as a foundation for further analysis and experimentation in the field of epidemiological modeling.